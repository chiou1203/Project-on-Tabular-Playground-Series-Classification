{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c2a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import ipynb\n",
    "import math\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2eab873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>m3_missing</th>\n",
       "      <th>m5_missing</th>\n",
       "      <th>attribute_2*3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26570</td>\n",
       "      <td>0</td>\n",
       "      <td>119.57</td>\n",
       "      <td>0</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>13.772</td>\n",
       "      <td>13.659</td>\n",
       "      <td>16.825</td>\n",
       "      <td>13.742</td>\n",
       "      <td>17.710</td>\n",
       "      <td>634.612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26571</td>\n",
       "      <td>0</td>\n",
       "      <td>113.51</td>\n",
       "      <td>0</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.473</td>\n",
       "      <td>17.468</td>\n",
       "      <td>16.708</td>\n",
       "      <td>14.776</td>\n",
       "      <td>14.102</td>\n",
       "      <td>537.037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26572</td>\n",
       "      <td>0</td>\n",
       "      <td>112.16</td>\n",
       "      <td>0</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>18.086</td>\n",
       "      <td>10.907</td>\n",
       "      <td>13.363</td>\n",
       "      <td>15.737</td>\n",
       "      <td>17.065</td>\n",
       "      <td>16.021</td>\n",
       "      <td>658.995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26573</td>\n",
       "      <td>0</td>\n",
       "      <td>112.72</td>\n",
       "      <td>0</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>16.163</td>\n",
       "      <td>10.933</td>\n",
       "      <td>15.501</td>\n",
       "      <td>15.667</td>\n",
       "      <td>12.620</td>\n",
       "      <td>16.111</td>\n",
       "      <td>594.301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26574</td>\n",
       "      <td>0</td>\n",
       "      <td>208.00</td>\n",
       "      <td>0</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>17.849</td>\n",
       "      <td>11.941</td>\n",
       "      <td>16.070</td>\n",
       "      <td>16.183</td>\n",
       "      <td>13.324</td>\n",
       "      <td>17.150</td>\n",
       "      <td>801.044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  product_code  loading  attribute_0 attribute_1  attribute_2  \\\n",
       "0  26570             0   119.57            0  material_6            6   \n",
       "1  26571             0   113.51            0  material_6            6   \n",
       "2  26572             0   112.16            0  material_6            6   \n",
       "3  26573             0   112.72            0  material_6            6   \n",
       "4  26574             0   208.00            0  material_6            6   \n",
       "\n",
       "   attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n",
       "0            4              6              9              6  ...   \n",
       "1            4             11              8              0  ...   \n",
       "2            4              8             12              4  ...   \n",
       "3            4              8             11             10  ...   \n",
       "4            4             14             16              8  ...   \n",
       "\n",
       "   measurement_11  measurement_12  measurement_13  measurement_14  \\\n",
       "0          18.070          13.772          13.659          16.825   \n",
       "1             NaN          12.473          17.468          16.708   \n",
       "2          18.086          10.907          13.363          15.737   \n",
       "3          16.163          10.933          15.501          15.667   \n",
       "4          17.849          11.941          16.070          16.183   \n",
       "\n",
       "   measurement_15  measurement_16  measurement_17  m3_missing  m5_missing  \\\n",
       "0          13.742          17.710         634.612           0           0   \n",
       "1          14.776          14.102         537.037           0           0   \n",
       "2          17.065          16.021         658.995           0           0   \n",
       "3          12.620          16.111         594.301           0           0   \n",
       "4          13.324          17.150         801.044           0           0   \n",
       "\n",
       "   attribute_2*3  \n",
       "0             24  \n",
       "1             24  \n",
       "2             24  \n",
       "3             24  \n",
       "4             24  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data from the training csv\n",
    "#then, firsst encode character attributes into integer attributes for an easier modeling\n",
    "#3 additional columns are added, indicating the appereace of missing value and the product of attribute_2 and attribute_3\n",
    "\n",
    "\n",
    "datatest = pd.read_csv(r'C:\\Users\\user\\Desktop\\tabular-playground-series-aug-2022\\test.csv', delimiter=',', usecols = ['id','product_code','loading','attribute_0','attribute_1','attribute_2','attribute_3','measurement_0','measurement_1','measurement_2','measurement_3','measurement_4','measurement_5','measurement_0','measurement_6','measurement_7','measurement_0','measurement_8','measurement_9','measurement_10','measurement_11','measurement_12','measurement_13','measurement_14','measurement_15','measurement_16','measurement_17'])\n",
    "\n",
    "cleanup_numst1 = {\"attribute_0\": {\"material_5\": 0, \"material_7\": 1}}\n",
    "cleanup_numst2 = {\"product_code\": {\"F\": 0, \"G\": 1, \"H\": 2, \"I\": 3}}\n",
    "datatest = datatest.replace(cleanup_numst1)\n",
    "datatest = datatest.replace(cleanup_numst2)\n",
    "\n",
    "datatest['m3_missing'] = datatest['measurement_3'].isnull().astype(np.int8)\n",
    "datatest['m5_missing'] = datatest['measurement_5'].isnull().astype(np.int8)\n",
    "datatest['attribute_2*3'] = datatest['attribute_2'] * datatest['attribute_3']\n",
    "\n",
    "\n",
    "datatest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7210ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we then group the data by product_code\n",
    "#here we drop some redundent attributes and measurements to perform the first feature selection\n",
    "\n",
    "productf = datatest[datatest['product_code']==0].drop(['attribute_1', 'attribute_2', 'attribute_3'],axis=1)\n",
    "productg = datatest[datatest['product_code']==1].drop(['attribute_1', 'attribute_2', 'attribute_3'],axis=1)\n",
    "producth = datatest[datatest['product_code']==2].drop(['attribute_1', 'attribute_2', 'attribute_3'],axis=1)\n",
    "producti = datatest[datatest['product_code']==3].drop(['attribute_1', 'attribute_2', 'attribute_3'],axis=1)\n",
    "\n",
    "impute_f = productf.drop(['id', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16'],axis=1)\n",
    "impute_g = productg.drop(['id', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16'],axis=1)\n",
    "impute_h = producth.drop(['id', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16'],axis=1)\n",
    "impute_i = producti.drop(['id', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f85a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\user\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#the next step is to perform imputation for the missing value\n",
    "#for measurement17, it has significant correlation with other measurements,\n",
    "#so I use HuberRegressor to compute the coefficient and fill the missing value in measurement17\n",
    "\n",
    "test_f = impute_f.dropna(how='any')\n",
    "huberf_1 = HuberRegressor().fit(test_f.iloc[:,9].values.reshape(-1, 1),test_f.iloc[:,13].values.reshape(-1, 1))\n",
    "huberf_2 = HuberRegressor().fit(test_f.iloc[:,7].values.reshape(-1, 1),test_f.iloc[:,13].values.reshape(-1, 1))\n",
    "\n",
    "test_g = impute_g.dropna(how='any')\n",
    "huberg_1 = HuberRegressor().fit(test_g.iloc[:,9].values.reshape(-1, 1),test_g.iloc[:,13].values.reshape(-1, 1))\n",
    "huberg_2 = HuberRegressor().fit(test_g.iloc[:,7].values.reshape(-1, 1),test_g.iloc[:,13].values.reshape(-1, 1))\n",
    "huberg_3 = HuberRegressor().fit(test_g.iloc[:,11].values.reshape(-1, 1),test_g.iloc[:,13].values.reshape(-1, 1))\n",
    "\n",
    "test_h = impute_h.dropna(how='any')\n",
    "huberh_1 = HuberRegressor().fit(test_h.iloc[:,8].values.reshape(-1, 1),test_h.iloc[:,13].values.reshape(-1, 1))\n",
    "huberh_2 = HuberRegressor().fit(test_h.iloc[:,12].values.reshape(-1, 1),test_h.iloc[:,13].values.reshape(-1, 1))\n",
    "\n",
    "test_i = impute_i.dropna(how='any')\n",
    "huberi_1 = HuberRegressor().fit(test_i.iloc[:,11].values.reshape(-1, 1),test_i.iloc[:,13].values.reshape(-1, 1))\n",
    "huberi_2 = HuberRegressor().fit(test_i.iloc[:,5].values.reshape(-1, 1),test_i.iloc[:,13].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b5465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing using huberregressor according to productcode\n",
    "\n",
    "for i in range(len(impute_f)):\n",
    "    if(math.isnan(impute_f.iloc[i,13])==True and math.isnan(impute_f.iloc[i,9])==True):\n",
    "        impute_f.iloc[i,13] = huberf_2.predict(impute_f.iloc[i,7].reshape(-1, 1))\n",
    "        \n",
    "    elif(math.isnan(impute_f.iloc[i,13])==True and math.isnan(impute_f.iloc[i,9])==False):\n",
    "        impute_f.iloc[i,13] = huberf_1.predict(impute_f.iloc[i,9].reshape(-1, 1))\n",
    "\n",
    "        \n",
    "for i in range(len(impute_g)):\n",
    "    if(math.isnan(impute_g.iloc[i,13])==True and math.isnan(impute_g.iloc[i,9])==True and math.isnan(impute_g.iloc[i,7])==True):\n",
    "        impute_g.iloc[i,13] = huberg_3.predict(impute_g.iloc[i,11].reshape(-1, 1))\n",
    "        \n",
    "    elif(math.isnan(impute_g.iloc[i,13])==True and math.isnan(impute_g.iloc[i,9])==True):\n",
    "        impute_g.iloc[i,13] = huberg_2.predict(impute_g.iloc[i,7].reshape(-1, 1))\n",
    "        \n",
    "    elif(math.isnan(impute_g.iloc[i,13])==True and math.isnan(impute_g.iloc[i,9])==False):\n",
    "        impute_g.iloc[i,13] = huberg_1.predict(impute_g.iloc[i,9].reshape(-1, 1))\n",
    "\n",
    "        \n",
    "for i in range(len(impute_h)):\n",
    "    if(math.isnan(impute_h.iloc[i,13])==True and math.isnan(impute_h.iloc[i,8])==True):\n",
    "        impute_h.iloc[i,13] = huberh_2.predict(impute_h.iloc[i,12].reshape(-1, 1))\n",
    "        \n",
    "    elif(math.isnan(impute_h.iloc[i,13])==True and math.isnan(impute_h.iloc[i,8])==False):\n",
    "        impute_h.iloc[i,13] = huberh_1.predict(impute_h.iloc[i,8].reshape(-1, 1))\n",
    "\n",
    "        \n",
    "for i in range(len(impute_i)):\n",
    "    if(math.isnan(impute_i.iloc[i,13])==True and math.isnan(impute_i.iloc[i,11])==True):\n",
    "        impute_i.iloc[i,13] = huberi_2.predict(impute_i.iloc[i,5].reshape(-1, 1))\n",
    "        \n",
    "    elif(math.isnan(impute_i.iloc[i,13])==True and math.isnan(impute_i.iloc[i,11])==False):\n",
    "        impute_i.iloc[i,13] = huberi_1.predict(impute_i.iloc[i,11].reshape(-1, 1))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb84113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing using KNN according to productcode\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "impute_f['loading'] = imputer.fit_transform(np.array(impute_f['loading']).reshape(-1,1))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "impute_g['loading'] = imputer.fit_transform(np.array(impute_g['loading']).reshape(-1,1))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "impute_h['loading'] = imputer.fit_transform(np.array(impute_h['loading']).reshape(-1,1))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "impute_i['loading'] = imputer.fit_transform(np.array(impute_i['loading']).reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8edf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after imputing, drop unnecessary measurements again to create the final feature selected\n",
    "\n",
    "impute_f = impute_f.drop(['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9'],axis=1)\n",
    "impute_g = impute_g.drop(['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9'],axis=1)\n",
    "impute_h = impute_h.drop(['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9'],axis=1)\n",
    "impute_i = impute_i.drop(['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6446650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a fuction to perform scaling before feeding it to the model, here i just use StandardScaler\n",
    "\n",
    "def scaling(data):\n",
    "    scaler = StandardScaler()    \n",
    "    select_feature = ['measurement_0','measurement_1', 'measurement_2', 'loading', 'measurement_17','attribute_2*3']\n",
    "    scaled = scaler.fit_transform(data[select_feature])\n",
    "\n",
    "    new = data.copy()\n",
    "    new[select_feature] = scaled\n",
    "    assert len(data) == len(new)\n",
    "\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48f4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the data after preprocessing to produce the final testing data\n",
    "\n",
    "\n",
    "framest = [impute_f, impute_g, impute_h, impute_i]\n",
    "test=pd.concat(framest)\n",
    "X_test = test.drop(['product_code'], axis=1)\n",
    "X_test = scaling(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e05ad672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18599365, 0.1631584 , 0.17514629, ..., 0.14546447, 0.21756607,\n",
       "       0.16200819])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model saved earlier, and compute the predictions on the testing data with a balanced weight on every model\n",
    "\n",
    "predictions = np.zeros(len(X_test))\n",
    "for i in range(10):\n",
    "    model = pickle.load(open('finalized_model' + str(i) + '.sav', 'rb'))\n",
    "    predictions += model.predict_proba(X_test)[:,1] / 10\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4722cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the final submission csv and we write the final prediction on it\n",
    "\n",
    "dfsub = pd.read_csv(r'C:\\Users\\user\\Desktop\\tabular-playground-series-aug-2022\\sample_submission.csv', delimiter=',', usecols = ['id','failure'])\n",
    "dfsub['failure'] = rankdata(predictions)\n",
    "\n",
    "os.makedirs('finalprojectml', exist_ok=True)\n",
    "dfsub.to_csv('finalprojectml/109550092_submissions.csv',index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
